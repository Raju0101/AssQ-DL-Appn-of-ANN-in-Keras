{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbea75b-939c-4e32-915d-9c5a72bb0bcc",
   "metadata": {},
   "source": [
    "## AssQ-DL-Implementation of ANN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b65c0-e3e6-46af-a9fd-beb5e4b64a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdfbe4-bcc4-4517-9f31-aeed078f7dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "To install the latest versions of TensorFlow and Keras, \n",
    "you can use the following pip commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa50e72-23b5-40d5-8d1c-d534e94e171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.8)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.4)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.11)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.57.0 keras-2.13.1 libclang-16.0.6 markdown-3.4.4 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.33.0 termcolor-2.3.0 werkzeug-2.3.7 wrapt-1.15.0\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.13.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow\n",
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9af1b44-edfe-4b29-b69d-32b3746194fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5448b-e220-4a18-b203-7dcb5b51f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "Keep in mind that the commands and code above assume you have Python and pip properly \n",
    "set up in your environment. Also, make sure you're using a virtual environment if desired to\n",
    "avoid conflicts with other packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39423140-ff7a-4555-b9ec-3fcfe64d46de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cdee9e-442c-4a4d-8b80-e0fe602ad1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Load the Wine Quality dataset and explore its dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6572caf-ec70-44ec-97e1-fd8ebe6f02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    " the Wine Quality dataset is a popular dataset for regression tasks. It contains various \n",
    "    chemical properties of wines and their associated quality ratings. You can load it using \n",
    "    the pandas library in Python. If you don't have it installed, you can install it using:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2b8122-cf57-4568-9a27-6b751726149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.5)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61eb6f3c-2228-419f-9981-dadc6849cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4898\n",
      "Number of columns: 12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Display the dimensions of the dataset\n",
    "rows, columns = wine_data.shape\n",
    "print(\"Number of rows:\", rows)\n",
    "print(\"Number of columns:\", columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3fddf-3868-4b8b-a9cc-9b7bfded0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "This code snippet will load the dataset from the provided URL and then \n",
    "print the number of rows and columns in the dataset. The dataset contains \n",
    "information about various chemical properties of white wines and their quality ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6177fb9-d560-4854-a848-571a66d4c3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da332de7-11fb-417c-a34a-c9f3d638dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Check for null values, identify categorical variables, and encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f87c9-60ce-4a65-a6aa-b90b97945779",
   "metadata": {},
   "outputs": [],
   "source": [
    "To check for null values, identify categorical variables, and encode them, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bac8410-181c-41e9-8d00-511d73b6cd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value counts:\n",
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "dtype: int64\n",
      "Categorical variables:\n",
      "Index([], dtype='object')\n",
      "Encoded dataset dimensions - rows: 4898\n",
      "Encoded dataset dimensions - columns: 12\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Check for null values\n",
    "null_counts = wine_data.isnull().sum()\n",
    "print(\"Null value counts:\")\n",
    "print(null_counts)\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_vars = wine_data.select_dtypes(include=['object']).columns\n",
    "print(\"Categorical variables:\")\n",
    "print(categorical_vars)\n",
    "\n",
    "# Encode categorical variables\n",
    "wine_data_encoded = pd.get_dummies(wine_data, columns=categorical_vars)\n",
    "\n",
    "# Display the dimensions of the encoded dataset\n",
    "encoded_rows, encoded_columns = wine_data_encoded.shape\n",
    "print(\"Encoded dataset dimensions - rows:\", encoded_rows)\n",
    "print(\"Encoded dataset dimensions - columns:\", encoded_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4225db5-1b82-44d5-8faa-da94e182daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, isnull().sum() is used to count the null values in each column of \n",
    "the dataset. The select_dtypes() function helps identify columns with categorical data types.\n",
    "The pd.get_dummies() function is used to one-hot encode the categorical variables.\n",
    "This will create new columns for each category in the categorical variables.\n",
    "The dimensions of the encoded dataset are then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3246c3-5112-4a81-88cd-7b83c7868f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839d9fc-c9a6-4941-af93-810bac58b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Separate the features and target variables from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ad44d-2157-445d-a387-eff02af75b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "To separate the features and target variables from the dataset, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f898009-90e7-4cc0-b64c-a97f91cf7848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (3918, 11)\n",
      "Test features shape: (980, 11)\n",
      "Train target shape: (3918,)\n",
      "Test target shape: (980,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Separate features and target variable\n",
    "features = wine_data.drop(columns=['quality'])  # Drop the 'quality' column\n",
    "target = wine_data['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the dimensions of the datasets\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Test features shape:\", test_features.shape)\n",
    "print(\"Train target shape:\", train_target.shape)\n",
    "print(\"Test target shape:\", test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812167a-3e5d-47a9-a445-ad973ce58dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the drop() function is used to remove the 'quality' column from the features,\n",
    "and the 'quality' column becomes the target variable. The train_test_split() function is \n",
    "then used to split the data into training and testing sets. \n",
    "The dimensions of the resulting datasets are printed to verify the separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e0f92-b059-4a34-92fe-282d1b6ccf69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c545ab-085b-4be1-b99a-a5303f51252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Perform a train-test split, dividing the data into training, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d92f4d1-b02b-4469-99dc-736d519668a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "To perform a train-test split and further divide the data into training, validation, \n",
    "and test datasets, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "522cf518-96ba-4d5e-96fe-8017d44f44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (3428, 11)\n",
      "Validation features shape: (735, 11)\n",
      "Test features shape: (735, 11)\n",
      "Train target shape: (3428,)\n",
      "Validation target shape: (735,)\n",
      "Test target shape: (735,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Separate features and target variable\n",
    "features = wine_data.drop(columns=['quality'])  # Drop the 'quality' column\n",
    "target = wine_data['quality']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_features, temp_features, train_target, temp_target = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "validation_features, test_features, validation_target, test_target = train_test_split(temp_features, temp_target, test_size=0.5, random_state=42)\n",
    "\n",
    "# Display the dimensions of the datasets\n",
    "print(\"Train features shape:\", train_features.shape)\n",
    "print(\"Validation features shape:\", validation_features.shape)\n",
    "print(\"Test features shape:\", test_features.shape)\n",
    "print(\"Train target shape:\", train_target.shape)\n",
    "print(\"Validation target shape:\", validation_target.shape)\n",
    "print(\"Test target shape:\", test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf669e-cee8-45fe-99de-95f1070942ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the data is first divided into training and the rest (temp) using train_test_split(). \n",
    "Then, the temp data is further divided into validation and test sets. This will result in three \n",
    "sets of features and target variables: training, validation, and test. The dimensions of these\n",
    "datasets are printed to verify the split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750628b8-f6aa-4c84-8099-b2f46d2f72b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd822dc-eb18-483e-b149-890ed4310468",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. Scale the dataset using an appropriate scaling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73a552-70e6-48d0-9d6a-1894f1d75a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaling the features of a dataset is an important preprocessing step to ensure that all \n",
    "features have similar scales. A common scaling technique is Standardization (Z-score normalization),\n",
    "which scales the features to have zero mean and unit variance. You can use the StandardScaler \n",
    "from the sklearn.preprocessing module to achieve this. \n",
    "Here's how you can scale the dataset using Standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a6cdc1-eb11-4853-8ea8-30385cc28d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features of the training set:\n",
      "[[-0.31132265 -0.28780076 -0.27645327 ... -1.13031916  0.0940735\n",
      "  -1.14685943]\n",
      " [ 1.10470658 -0.18935432  1.30066456 ... -1.06354794 -1.49278025\n",
      "   0.64257527]\n",
      " [-0.66532995 -0.48469365 -0.02743466 ...  0.87281754 -0.61119484\n",
      "   0.56123733]\n",
      " ...\n",
      " [ 0.86870171 -0.09090788  1.54968316 ... -1.13031916  0.35854912\n",
      "   0.72391321]\n",
      " [-0.66532995 -0.3862472  -0.35945947 ... -0.12875081 -0.963829\n",
      "   0.07320968]\n",
      " [ 1.45871389 -0.09090788  0.13857774 ...  0.2051053   1.24013454\n",
      "  -0.0894662 ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "wine_data = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Separate features and target variable\n",
    "features = wine_data.drop(columns=['quality'])  # Drop the 'quality' column\n",
    "target = wine_data['quality']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_features, temp_features, train_target, temp_target = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "validation_features, test_features, validation_target, test_target = train_test_split(temp_features, temp_target, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "validation_features_scaled = scaler.transform(validation_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# Display the scaled features of the training set\n",
    "print(\"Scaled features of the training set:\")\n",
    "print(train_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d34f52-240e-4f2d-b194-7edb013008c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the StandardScaler is used to scale the features. \n",
    "The fit_transform() method is applied to the training features, and the transform() method \n",
    "is applied to the validation and test features using the scaling parameters learned from the training data.\n",
    "The scaled features of the training set are then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973a4ec-71bd-4591-8303-0af859d53cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93982e7d-f8df-47c0-95b0-8e83fc65d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. Design and implement at least two hidden layers and an output layer for the binary categorical \n",
    "variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008b9b1-4158-4eb9-bf46-9b7699c45544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Sure, here's an example of how you can design and implement a neural network with at least \n",
    "two hidden layers and an output layer for binary categorical variables using TensorFlow and Keras. In this example,\n",
    "I'll assume you have already preprocessed the data and have scaled features and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "280255c1-248f-41f0-a9d0-a9ead4a5ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the number of features in your dataset\n",
    "num_features = 11  # Replace this with the actual number of features\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(num_features,)))  # Input layer\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))  # First hidden layer\n",
    "model.add(keras.layers.Dropout(0.3))  # Dropout\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Second hidden layer\n",
    "model.add(keras.layers.Dropout(0.3))  # Dropout\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b658d-cbc5-42b1-a706-58704f0f3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we're creating a neural network model using the Sequential API from Keras.\n",
    "The model consists of an input layer with the number of features as the input shape.\n",
    "We then add two hidden layers with ReLU activation functions and dropout layers to \n",
    "prevent overfitting. The output layer has a sigmoid activation function suitable for binary classification.\n",
    "\n",
    "The model is compiled with the Adam optimizer and binary cross-entropy loss function. \n",
    "It's then trained using the training data and validated using the validation data.\n",
    "After training, the model is evaluated on the test set, and the test accuracy is printed.\n",
    "\n",
    "You'll need to adjust the architecture, hyperparameters, and other aspects of the model based \n",
    "on your specific problem and data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f7987-86f2-4ddb-8989-dcad2080289a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9b4da-df6e-4979-8df6-2889b9621744",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. Create a Sequential model in Keras and add the previously designed layers to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbbf6f-5609-4c55-8093-a0ac7ef7013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here's how you can create a Sequential model in Keras and add the previously designed layers to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13f54324-db2d-4e3e-b311-44baab261e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 128)               1408      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9729 (38.00 KB)\n",
      "Trainable params: 9729 (38.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the number of features in your dataset\n",
    "num_features = 10  # Replace this with the actual number of features\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Add layers to the model\n",
    "model.add(keras.layers.Input(shape=(num_features)))  # Input layer\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu'))  # First hidden layer\n",
    "model.add(keras.layers.Dropout(0.3))  # Dropout\n",
    "\n",
    "model.add(keras.layers.Dense(64, activation='relu'))  # Second hidden layer\n",
    "model.add(keras.layers.Dropout(0.3))  # Dropout\n",
    "\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4c75b-7e50-41db-80c9-6339182ac450",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we create a Sequential model using the keras.Sequential() constructor.\n",
    "\n",
    "We then use the add() method to add layers to the model one by one. \n",
    "This follows the architecture you previously designed: an input layer, two hidden layers with dropout,\n",
    "and an output layer.\n",
    "\n",
    "Finally, the model is compiled with the Adam optimizer and binary cross-entropy loss function, and its\n",
    "summary is printed to provide an overview of the layers and parameters. Remember to replace num_features\n",
    "with the actual number of features in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24230ac9-7cc9-4102-b455-3a63f666198a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b79b8b84-2cb3-443b-a8c0-a6f9047364f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               1408      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9729 (38.00 KB)\n",
      "Trainable params: 9729 (38.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the number of features in your dataset\n",
    "num_features = 10  # Replace this with the actual number of features\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    \n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    \n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    \n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2375972-ca92-497a-95d6-f8e3b5a4a739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1408      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9729 (38.00 KB)\n",
      "Trainable params: 9729 (38.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Define the number of features in your dataset\n",
    "num_features = 10  # Replace this with the actual number of features\n",
    "\n",
    "# Create a Sequential model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    \n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    \n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    \n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e43c86-4128-4429-b8d0-906e1968de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the entire Sequential model is created and all the layers are \n",
    "added within the keras.Sequential() constructor. This follows the architecture you \n",
    "previously designed: an input layer, two hidden layers with dropout, and an output layer.\n",
    "\n",
    "After adding the layers, the model is compiled with the Adam optimizer and binary cross-\n",
    "entropy loss function, and its summary is printed to provide an overview of the layers and parameters.\n",
    "As before, replace num_features with the actual number of features in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b8f8e-5c6a-4d5e-9a69-fdefd41df212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd8eba9-893f-4be7-b4f4-293dad1c1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9. Print the summary of the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7070d-e159-442c-bc7c-09c02088ec65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0f32146-5610-4b32-898d-22ae78311320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load your data and preprocess as needed\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5dbef-07be-4907-97f1-e5f55256a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, the summary() method is called on the model object to print a summary of the model's architecture,\n",
    "including the layers, output shapes, and number of parameters.\n",
    "\n",
    "Remember to replace num_features with the actual number of features in your dataset and\n",
    "adjust the data loading and preprocessing steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101627a4-87ea-437d-be2f-6fbc60ee079e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd067cfc-70eb-4024-9cb7-50ac1ba9c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10. Set the loss function(‘binary_crossentropy’), optimizer, and include the accuracy metric in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78e42d-6a18-499d-b8e9-cb0a92ffc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can set the loss function to 'binary_crossentropy',\n",
    "choose an optimizer (e.g., Adam), and include the accuracy metric in your Keras model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fa06cea-8e62-4a9a-af3b-84ad02c8f0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load your data and preprocess as needed\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667a751-674c-4f3e-8606-b92da2e60fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "The compile() method is used to set the optimizer to 'adam', the loss function\n",
    "to 'binary_crossentropy', and the metrics to include 'accuracy'.\n",
    "\n",
    "The accuracy metric will be used to evaluate the model's performance during training and evaluation.\n",
    "\n",
    "Remember to replace num_features with the actual number of features in your dataset and adjust the data \n",
    "loading and preprocessing steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbea99a-6d10-4c22-a00d-2fa61c962521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea765f-b1db-4a0b-932c-aa8d5d81fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11. Compile the model with the specified loss function, optimizer, and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449685c-eab0-4310-ba49-3dec501c6df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "To compile the model with the specified loss function, optimizer, and metrics, you can use the compile() \n",
    "method of your Keras model. Here's how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e20589fa-0070-4857-b15d-2d3531be4bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load your data and preprocess as needed\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5107bc-9b49-421d-b00c-be6d84a59156",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "The compile() method is used to specify the 'adam' optimizer, the 'binary_crossentropy' loss function \n",
    "(suitable for binary classification), and the metrics you want to track during training and evaluation\n",
    "(in this case, 'accuracy').\n",
    "\n",
    "The summary() method prints a summary of the model architecture, including the layers, output shapes,\n",
    "and number of parameters.\n",
    "\n",
    "Remember to replace num_features with the actual number of features in your dataset and adjust the data\n",
    "loading and preprocessing steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502caad9-a05c-422e-953e-c4317951d0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d7d25-4ec1-44e5-ac13-90ba092dfc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q12. Fit the model to the training data using appropriate batch size and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd614537-4b5c-48c9-9542-f1f1dd88cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "To fit the model to the training data using an appropriate batch size and number of epochs,\n",
    "you can use the fit() method of your Keras model. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a87c91c3-1c73-4ccb-b7d3-35b34abd3639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 3s 14ms/step - loss: -87.4749 - accuracy: 0.0000e+00 - val_loss: -314.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -1204.2526 - accuracy: 0.0000e+00 - val_loss: -2686.9431 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -5917.4307 - accuracy: 0.0000e+00 - val_loss: -10120.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -17255.0098 - accuracy: 0.0000e+00 - val_loss: -25619.9453 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 1s 9ms/step - loss: -38442.7812 - accuracy: 0.0000e+00 - val_loss: -52056.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -71346.2891 - accuracy: 0.0000e+00 - val_loss: -91376.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -119305.3359 - accuracy: 0.0000e+00 - val_loss: -146009.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -183716.5625 - accuracy: 0.0000e+00 - val_loss: -217314.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -264459.6250 - accuracy: 0.0000e+00 - val_loss: -307558.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -366484.3125 - accuracy: 0.0000e+00 - val_loss: -417133.0312 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9c9870fd00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load your data and preprocess as needed\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data\n",
    "batch_size = 32  # Adjust as needed\n",
    "epochs = 10  # Adjust as needed\n",
    "\n",
    "model.fit(train_features_scaled, train_target, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(validation_features_scaled, validation_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6430d-5c90-40d4-b270-cefbe5fe69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "In this code:\n",
    "\n",
    "The fit() method is used to train the model using the training data.\n",
    "The batch_size parameter specifies the number of samples per gradient update.\n",
    "You can adjust it based on your available memory and computational resources.\n",
    "The epochs parameter specifies the number of times the entire training dataset is iterated over.\n",
    "You can adjust it based on the convergence of your model.\n",
    "Remember to replace num_features with the actual number of features in your dataset, and adjust \n",
    "the data loading and preprocessing steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc8096-b9b4-4dce-ac65-cd14128b1101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed8d35-3ec9-4446-956b-1a3caf9a96ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q13. Obtain the model's parameters (weights and biases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ff1fa-054c-4e81-91b8-b0fbc2deb7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "To obtain the model's parameters (weights and biases), you can use the get_weights() method of each \n",
    "layer in your Keras model. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86d556e7-5874-4aa3-bf1a-9ff70584014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 4s 13ms/step - loss: -98.6178 - accuracy: 0.0000e+00 - val_loss: -349.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -1350.6334 - accuracy: 0.0000e+00 - val_loss: -3052.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -6749.9497 - accuracy: 0.0000e+00 - val_loss: -11683.5889 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -19880.6602 - accuracy: 0.0000e+00 - val_loss: -29576.8008 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -43802.4453 - accuracy: 0.0000e+00 - val_loss: -59710.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -81634.7109 - accuracy: 0.0000e+00 - val_loss: -104508.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -135734.7656 - accuracy: 0.0000e+00 - val_loss: -166449.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 1s 9ms/step - loss: -208611.7344 - accuracy: 0.0000e+00 - val_loss: -248113.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -301330.7188 - accuracy: 0.0000e+00 - val_loss: -349662.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -416089.5000 - accuracy: 0.0000e+00 - val_loss: -474695.1875 - val_accuracy: 0.0000e+00\n",
      "Model parameters (weights and biases):\n",
      "[[array([[ 1.4305387 , -1.2090349 ,  0.14068884, ..., -1.2298168 ,\n",
      "        -1.6727607 , -0.09681061],\n",
      "       [-0.12132458, -1.2374896 , -1.5213683 , ..., -0.76855904,\n",
      "         0.32458156, -0.83226866],\n",
      "       [ 0.8521986 , -0.05936807,  0.99805856, ..., -0.67505133,\n",
      "        -1.1294291 , -0.05369479],\n",
      "       ...,\n",
      "       [-1.6847237 ,  1.6186955 , -0.58655167, ...,  1.3730564 ,\n",
      "         1.2820864 ,  1.2621787 ],\n",
      "       [-0.6792713 , -0.4874247 ,  0.7561732 , ...,  0.27045906,\n",
      "        -0.46420482,  0.3797429 ],\n",
      "       [-2.0133345 ,  1.5523274 , -1.9819628 , ...,  1.7130737 ,\n",
      "         1.8185203 ,  1.8080236 ]], dtype=float32), array([1.9497522, 2.031799 , 2.020902 , 1.9402602, 2.0132818, 1.9743392,\n",
      "       2.026105 , 1.9946586, 1.9918168, 1.9926397, 1.9746902, 2.0058274,\n",
      "       2.0116816, 1.9869652, 1.9960275, 1.9923193, 1.9947993, 2.0027065,\n",
      "       1.992899 , 1.9806753, 1.9976945, 1.9958098, 1.9605571, 1.9743826,\n",
      "       1.990183 , 1.9940615, 2.0232537, 1.9984925, 1.9938989, 2.0040588,\n",
      "       2.0130124, 2.0120244, 1.941729 , 2.0017705, 2.0149329, 1.982186 ,\n",
      "       1.9848672, 2.0019414, 2.003594 , 2.0014527, 2.0118368, 1.9416587,\n",
      "       2.0073092, 1.9590498, 1.9904416, 1.9799026, 2.0048432, 1.9583788,\n",
      "       1.9849846, 1.9755443, 1.9947542, 2.0098002, 2.007449 , 1.9731451,\n",
      "       2.0002978, 1.9697119, 1.959456 , 1.9998177, 1.9968957, 1.9812707,\n",
      "       2.001541 , 1.9823736, 2.0020068, 1.9923409, 1.9867094, 1.9878035,\n",
      "       2.0052698, 2.0291731, 2.011457 , 2.0058424, 2.02642  , 1.9860615,\n",
      "       1.9917321, 1.9680161, 1.9986938, 1.995107 , 2.0018983, 2.0209126,\n",
      "       2.0033865, 2.0280156, 2.013482 , 2.0129578, 1.9879745, 1.9909987,\n",
      "       1.9923288, 2.000119 , 1.9939837, 1.9887553, 2.037397 , 1.9799472,\n",
      "       2.015371 , 2.0238163, 1.9966611, 1.9930264, 1.926954 , 1.9996616,\n",
      "       2.0040834, 2.002702 , 2.0031788, 1.9889388, 2.0322852, 1.9801123,\n",
      "       1.978433 , 1.9999838, 1.9862963, 1.954108 , 1.9966983, 2.0003893,\n",
      "       1.9980162, 2.006877 , 1.9737707, 2.0158367, 2.0191898, 2.0135703,\n",
      "       2.0023506, 1.9976057, 1.9716735, 1.9556005, 1.9910849, 1.9981884,\n",
      "       2.017079 , 1.948901 , 1.9968853, 1.992147 , 2.0092645, 2.009943 ,\n",
      "       1.9687237, 1.9911721], dtype=float32)], [], [array([[1.7725356, 1.8180665, 1.8730587, ..., 1.7013394, 1.7760539,\n",
      "        1.7672899],\n",
      "       [1.9521325, 1.8304214, 1.9316571, ..., 1.824975 , 1.9248415,\n",
      "        2.005778 ],\n",
      "       [1.9969672, 1.7679659, 1.8741192, ..., 1.6916397, 1.9530008,\n",
      "        2.065588 ],\n",
      "       ...,\n",
      "       [1.936931 , 1.9509   , 1.8787922, ..., 1.9876399, 2.0282457,\n",
      "        1.8216122],\n",
      "       [1.883885 , 1.9556266, 1.9373924, ..., 1.9910984, 2.0035424,\n",
      "        1.9647605],\n",
      "       [1.9065591, 2.008621 , 2.0556092, ..., 1.8942723, 1.917971 ,\n",
      "        1.9425391]], dtype=float32), array([ 1.5250365 ,  1.5987177 ,  1.7116708 , -0.03464033,  1.7107991 ,\n",
      "        1.6563224 ,  1.6122973 ,  1.7082211 ,  1.6504799 , -0.03057987,\n",
      "       -0.04310309,  1.616438  , -0.03347699,  0.34549636, -0.03181734,\n",
      "       -0.03444445,  1.6728666 , -0.03616048, -0.0384545 ,  1.5297495 ,\n",
      "        1.5156087 ,  1.5477713 ,  1.5946689 ,  1.5392672 , -0.03576303,\n",
      "        1.5632753 , -0.03831833,  1.6015359 , -0.04193939,  1.6807181 ,\n",
      "        1.5271391 ,  1.6048975 ,  1.5538782 ,  1.5886602 ,  1.6823674 ,\n",
      "        1.5661622 ,  1.7044203 , -0.03196437, -0.03624873,  1.5650212 ,\n",
      "        1.5884773 ,  1.6422892 , -0.03151996,  1.6585435 , -0.03310146,\n",
      "       -0.0355052 , -0.03636217,  1.5188645 , -0.03357225,  1.6517463 ,\n",
      "       -0.04249418,  1.5109235 ,  1.5323488 ,  1.633606  ,  1.5523111 ,\n",
      "        1.5277191 , -0.03668334, -0.03559585,  1.5279067 , -0.03923426,\n",
      "        1.5914685 ,  1.6708485 ,  1.7080593 ,  1.6790152 ], dtype=float32)], [], [array([[ 2.3487904 ],\n",
      "       [ 2.2308264 ],\n",
      "       [ 2.0776834 ],\n",
      "       [-0.09404538],\n",
      "       [ 2.0808263 ],\n",
      "       [ 2.0042975 ],\n",
      "       [ 2.202619  ],\n",
      "       [ 2.0876563 ],\n",
      "       [ 2.1542253 ],\n",
      "       [-0.12850042],\n",
      "       [-0.14908607],\n",
      "       [ 2.19726   ],\n",
      "       [-0.05282799],\n",
      "       [ 0.4438956 ],\n",
      "       [-0.20356698],\n",
      "       [-0.13111338],\n",
      "       [ 2.0449626 ],\n",
      "       [-0.17407727],\n",
      "       [-0.21920185],\n",
      "       [ 2.3329468 ],\n",
      "       [ 2.3386025 ],\n",
      "       [ 2.3180068 ],\n",
      "       [ 2.2070978 ],\n",
      "       [ 2.297037  ],\n",
      "       [-0.22970052],\n",
      "       [ 2.2828076 ],\n",
      "       [-0.25798962],\n",
      "       [ 2.249064  ],\n",
      "       [-0.16965759],\n",
      "       [ 2.056878  ],\n",
      "       [ 2.3541079 ],\n",
      "       [ 2.1827974 ],\n",
      "       [ 2.2641718 ],\n",
      "       [ 2.2419784 ],\n",
      "       [ 2.1179316 ],\n",
      "       [ 2.2539952 ],\n",
      "       [ 2.081172  ],\n",
      "       [-0.12833306],\n",
      "       [-0.09821174],\n",
      "       [ 2.2421198 ],\n",
      "       [ 2.2021794 ],\n",
      "       [ 2.1761403 ],\n",
      "       [-0.13520315],\n",
      "       [ 2.1346216 ],\n",
      "       [-0.06099517],\n",
      "       [-0.02449737],\n",
      "       [-0.06322039],\n",
      "       [ 2.3346155 ],\n",
      "       [-0.14591224],\n",
      "       [ 2.129744  ],\n",
      "       [-0.24219601],\n",
      "       [ 2.3703775 ],\n",
      "       [ 2.3363001 ],\n",
      "       [ 2.1570923 ],\n",
      "       [ 2.2968662 ],\n",
      "       [ 2.3400242 ],\n",
      "       [-0.13358872],\n",
      "       [-0.23117383],\n",
      "       [ 2.367093  ],\n",
      "       [-0.10345482],\n",
      "       [ 2.2359402 ],\n",
      "       [ 2.0611632 ],\n",
      "       [ 2.0734458 ],\n",
      "       [ 2.104789  ]], dtype=float32), array([1.0760411], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load your data and preprocess as needed\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data\n",
    "batch_size = 32  # Adjust as needed\n",
    "epochs = 10  # Adjust as needed\n",
    "model.fit(train_features_scaled, train_target, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(validation_features_scaled, validation_target))\n",
    "\n",
    "# Obtain model parameters (weights and biases)\n",
    "model_params = []\n",
    "for layer in model.layers:\n",
    "    layer_params = layer.get_weights()\n",
    "    model_params.append(layer_params)\n",
    "\n",
    "print(\"Model parameters (weights and biases):\")\n",
    "print(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c2678-93b5-4bdd-8f86-653870112ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "After training the model using the fit() method, you can iterate through each layer in the model using a loop.\n",
    "For each layer, you can use the get_weights() method to retrieve the weights and biases of that layer.\n",
    "The model's parameters are stored in the model_params list, which you can print to see the weights and biases.\n",
    "Remember to replace num_features with the actual number of features in your dataset and adjust the data loading \n",
    "and preprocessing steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edf93a-7ffc-4719-a69b-bc0cc2f91d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3395b-241b-4932-be2e-7c3e5da733e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q14. Store the model's training history as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74100574-ff51-457b-9c57-77d94b4eb884",
   "metadata": {},
   "outputs": [],
   "source": [
    "To store the model's training history as a Pandas DataFrame, you can capture the return value of\n",
    "the fit() method, which is a history object containing training and validation metrics for each epoch.\n",
    "You can then convert this history\n",
    "object into a DataFrame. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "454ad7c4-efae-46b7-84e0-db62a940572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 3s 13ms/step - loss: -73.2549 - accuracy: 0.0000e+00 - val_loss: -265.6037 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -1054.3671 - accuracy: 0.0000e+00 - val_loss: -2370.2493 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -5224.2480 - accuracy: 0.0000e+00 - val_loss: -8951.7012 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -15300.8145 - accuracy: 0.0000e+00 - val_loss: -22806.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 1s 6ms/step - loss: -34402.2539 - accuracy: 0.0000e+00 - val_loss: -46891.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -64692.3672 - accuracy: 0.0000e+00 - val_loss: -83110.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 1s 6ms/step - loss: -108615.7500 - accuracy: 0.0000e+00 - val_loss: -133557.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 1s 6ms/step - loss: -167549.2969 - accuracy: 0.0000e+00 - val_loss: -199374.1719 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -243426.8125 - accuracy: 0.0000e+00 - val_loss: -282347.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -336793.5312 - accuracy: 0.0000e+00 - val_loss: -383695.0625 - val_accuracy: 0.0000e+00\n",
      "            loss  accuracy       val_loss  val_accuracy\n",
      "0     -73.254852       0.0    -265.603668           0.0\n",
      "1   -1054.367065       0.0   -2370.249268           0.0\n",
      "2   -5224.248047       0.0   -8951.701172           0.0\n",
      "3  -15300.814453       0.0  -22806.208984           0.0\n",
      "4  -34402.253906       0.0  -46891.390625           0.0\n",
      "5  -64692.367188       0.0  -83110.375000           0.0\n",
      "6 -108615.750000       0.0 -133557.125000           0.0\n",
      "7 -167549.296875       0.0 -199374.171875           0.0\n",
      "8 -243426.812500       0.0 -282347.750000           0.0\n",
      "9 -336793.531250       0.0 -383695.062500           0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data and preprocess as needed\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data\n",
    "batch_size = 32  # Adjust as needed\n",
    "epochs = 10  # Adjust as needed\n",
    "history = model.fit(train_features_scaled, train_target, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(validation_features_scaled, validation_target))\n",
    "\n",
    "# Store training history as a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Print the training history DataFrame\n",
    "print(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398b960-11e8-4ca2-b505-ecb45555aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "After training the model using the fit() method, the training history is captured in the history object.\n",
    "The history object contains dictionaries for each metric (e.g., 'loss' and 'val_loss' for training and \n",
    "                                                          validation loss, 'accuracy' and \n",
    "                                                          'val_accuracy' for training and validation accuracy).\n",
    "The pd.DataFrame() function is used to convert the history object into a Pandas DataFrame named history_df.\n",
    "Remember to replace num_features with the actual number of features in your dataset and adjust the data loading \n",
    "and preprocessing steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70015ad5-5623-4f44-9fce-cd63fd585369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d5251-e254-44e2-9c17-32b8042c5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q15. Plot the training history (e.g., accuracy and loss) using suitable visualization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3277b6e-9311-4a7e-9e06-5ab4608b3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "To plot the training history, you can use the matplotlib library to create visualizations of the\n",
    "training and validation metrics such as accuracy and loss. \n",
    "Here's an example of how you can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9593ded3-146d-4ade-a87f-0f4b4832bf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_57 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 3s 14ms/step - loss: -91.7221 - accuracy: 0.0000e+00 - val_loss: -333.7036 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -1296.3098 - accuracy: 0.0000e+00 - val_loss: -2886.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -6277.9619 - accuracy: 0.0000e+00 - val_loss: -10785.6143 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -18300.6562 - accuracy: 0.0000e+00 - val_loss: -27059.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -40307.3359 - accuracy: 0.0000e+00 - val_loss: -54570.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -75100.8516 - accuracy: 0.0000e+00 - val_loss: -95956.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -125097.5156 - accuracy: 0.0000e+00 - val_loss: -153058.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -191531.8594 - accuracy: 0.0000e+00 - val_loss: -228168.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -276396.2188 - accuracy: 0.0000e+00 - val_loss: -322485.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 1s 6ms/step - loss: -383947.8750 - accuracy: 0.0000e+00 - val_loss: -438927.9375 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data and preprocess as needed\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data\n",
    "batch_size = 32  # Adjust as needed\n",
    "epochs = 10  # Adjust as needed\n",
    "history = model.fit(train_features_scaled, train_target, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(validation_features_scaled, validation_target))\n",
    "\n",
    "# Store training history as a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Plot training history (accuracy and loss)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_df['accuracy'], label='Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_df['loss'], label='Loss')\n",
    "plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5cca73-880f-4f8b-8b80-9053747abbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "After training the model, the training history is captured in the history object.\n",
    "The training and validation accuracy and loss are stored in the history_df DataFrame.\n",
    "The matplotlib.pyplot library is used to create subplots for accuracy and loss visualizations.\n",
    "The plt.plot() function is used to plot the training and validation metrics over epochs.\n",
    "plt.legend(), plt.xlabel(), plt.ylabel(), and plt.title() are used to label and title the plots.\n",
    "plt.tight_layout() ensures proper spacing between subplots.\n",
    "plt.show() displays the plots.\n",
    "Remember to replace num_features with the actual number of features \n",
    "in your dataset and adjust the data loading and preprocessing steps as needed. Also, make sure you \n",
    "have the matplotlib library installed (pip install matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03822d36-e2d7-47b1-a974-11049e76fdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7987b-b72d-4c9c-8074-d8b55d937995",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q16. Evaluate the model's performance using the test dataset and report relevant metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a98e3-130d-4cca-86e4-cdc162922842",
   "metadata": {},
   "outputs": [],
   "source": [
    "To evaluate the model's performance using the test dataset and report relevant metrics such as\n",
    "accuracy and loss, you can use the evaluate() method of your Keras model.\n",
    "Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "843ed606-0eee-46c5-8d72-0583e4165726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 128)               1536      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9857 (38.50 KB)\n",
      "Trainable params: 9857 (38.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 3s 14ms/step - loss: -69.0493 - accuracy: 0.0000e+00 - val_loss: -261.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 1s 9ms/step - loss: -1107.9224 - accuracy: 0.0000e+00 - val_loss: -2555.8882 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -5836.0898 - accuracy: 0.0000e+00 - val_loss: -10146.2949 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -17571.9512 - accuracy: 0.0000e+00 - val_loss: -26074.0156 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 1s 9ms/step - loss: -39104.7969 - accuracy: 0.0000e+00 - val_loss: -52990.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 1s 6ms/step - loss: -73158.3672 - accuracy: 0.0000e+00 - val_loss: -93209.3203 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -121526.7109 - accuracy: 0.0000e+00 - val_loss: -148721.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 1s 7ms/step - loss: -186490.7969 - accuracy: 0.0000e+00 - val_loss: -221437.7188 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 1s 6ms/step - loss: -269294.2500 - accuracy: 0.0000e+00 - val_loss: -313062.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 1s 8ms/step - loss: -372767.6875 - accuracy: 0.0000e+00 - val_loss: -424728.7812 - val_accuracy: 0.0000e+00\n",
      "23/23 [==============================] - 0s 10ms/step - loss: -448437.0625 - accuracy: 0.0000e+00\n",
      "Test Loss: -448437.0625\n",
      "Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load your data and preprocess as needed\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(num_features,)),  # Input layer\n",
    "    keras.layers.Dense(128, activation='relu'),  # First hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(64, activation='relu'),  # Second hidden layer\n",
    "    keras.layers.Dropout(0.3),  # Dropout\n",
    "    keras.layers.Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Fit the model to the training data\n",
    "batch_size = 32  # Adjust as needed\n",
    "epochs = 10  # Adjust as needed\n",
    "history = model.fit(train_features_scaled, train_target, batch_size=batch_size, epochs=epochs,\n",
    "                    validation_data=(validation_features_scaled, validation_target))\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_features_scaled, test_target)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81fc5c-f716-46bc-8cfd-b3757b3d8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code:\n",
    "\n",
    "After training the model using the fit() method, you can use the evaluate() method to\n",
    "assess the model's performance on the test dataset.\n",
    "The evaluate() method returns the test loss and test accuracy, which are then printed as evaluation metrics.\n",
    "Remember to replace num_features with the actual number of features in your dataset and adjust the data \n",
    "loading and preprocessing steps as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff6bfa-3309-4bb2-a00d-e2741c29e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "...................................The End......................."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
